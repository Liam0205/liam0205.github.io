<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-touch-icon.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png?v=7.3.0">
  <link rel="mask-icon" href="/images/favicon/safari-pinned-tab.svg?v=7.3.0" color="#222">
  <link rel="manifest" href="/images/favicon/site.webmanifest">
  <meta name="msapplication-config" content="/images/favicon/browserconfig.xml">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta name="google-site-verification" content="TYuJQFuiVqfbFfJAkHfXigSDRIMibztxXxgl_iAaQhA">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="早在学习数学分析时，我就已经接触过卷积的概念。然而，彼时年少，水平有限，没有完整地理解卷积的概念和精髓。这个遗憾一直持续至今。接触到卷积神经网络（Convolution Neural Network, CNN）之后，旧事重提般地，想要了解清楚卷积的冲动就愈发强烈，终至此文。  这是一篇介绍性质的文章。文中的公式、动画效果限于网页的表现力，无法达至完美。本文有对应的 PDF 格式的幻灯片可供下载（离">
<meta name="keywords" content="Convolutions,CNN,Neural Network,Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="谈谈离散卷积和卷积神经网络">
<meta property="og:url" content="https://liam.page/2017/07/27/convolutions-and-convolution-neural-network/index.html">
<meta property="og:site_name" content="始终">
<meta property="og:description" content="早在学习数学分析时，我就已经接触过卷积的概念。然而，彼时年少，水平有限，没有完整地理解卷积的概念和精髓。这个遗憾一直持续至今。接触到卷积神经网络（Convolution Neural Network, CNN）之后，旧事重提般地，想要了解清楚卷积的冲动就愈发强烈，终至此文。  这是一篇介绍性质的文章。文中的公式、动画效果限于网页的表现力，无法达至完美。本文有对应的 PDF 格式的幻灯片可供下载（离">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://liam.page/uploads/images/MachineLearning/linear_time-invariant_system.png">
<meta property="og:image" content="https://liam.page/uploads/images/MachineLearning/automatic_investment_plan.gif">
<meta property="og:image" content="https://liam.page/uploads/images/MachineLearning/how_to_convolve.png">
<meta property="og:image" content="https://liam.page/uploads/images/MachineLearning/convolutions_on_images.gif">
<meta property="og:image" content="https://liam.page/uploads/images/MachineLearning/image_filter.png">
<meta property="og:image" content="https://liam.page/uploads/images/MachineLearning/pattern_reg_target.png">
<meta property="og:image" content="https://liam.page/uploads/images/MachineLearning/pattern_reg_dnn.png">
<meta property="og:image" content="https://liam.page/uploads/images/MachineLearning/pattern_reg_cases.png">
<meta property="og:image" content="https://liam.page/uploads/images/MachineLearning/pattern_reg_cnn.png">
<meta property="og:updated_time" content="2019-01-12T07:22:33.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="谈谈离散卷积和卷积神经网络">
<meta name="twitter:description" content="早在学习数学分析时，我就已经接触过卷积的概念。然而，彼时年少，水平有限，没有完整地理解卷积的概念和精髓。这个遗憾一直持续至今。接触到卷积神经网络（Convolution Neural Network, CNN）之后，旧事重提般地，想要了解清楚卷积的冲动就愈发强烈，终至此文。  这是一篇介绍性质的文章。文中的公式、动画效果限于网页的表现力，无法达至完美。本文有对应的 PDF 格式的幻灯片可供下载（离">
<meta name="twitter:image" content="https://liam.page/uploads/images/MachineLearning/linear_time-invariant_system.png">
  <link rel="alternate" href="/atom.xml" title="始终" type="application/atom+xml">
  <link rel="canonical" href="https://liam.page/2017/07/27/convolutions-and-convolution-neural-network/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>谈谈离散卷积和卷积神经网络 | 始终</title>
  <meta name="generator" content="Hexo 3.9.0">
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-44836433-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-44836433-1');
    }
  </script>








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">始终</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">不忘初心</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档<span class="badge">300</span></a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类<span class="badge">11</span></a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签<span class="badge">611</span></a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-系列">
      
    
      
    

    <a href="/series" rel="section"><i class="menu-item-icon fa fa-fw fa-book"></i> <br>系列</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-札记-&-留言板">
      
    
      
    

    <a href="/notes/" rel="section"><i class="menu-item-icon fa fa-fw fa-sticky-note"></i> <br>札记 & 留言板</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-英文">
      
    
      
    

    <a href="/en" rel="section"><i class="menu-item-icon fa fa-fw fa-link"></i> <br>英文</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
      </li>
    
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="https://liam.page/2017/07/27/convolutions-and-convolution-neural-network/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liam Huang">
      <meta itemprop="description" content="不忘初心，方得始终。">
      <meta itemprop="image" content="/images/avatar/avatar.webp">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="始终">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">谈谈离散卷积和卷积神经网络

          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2017 年 07 月 27 日 14:17:29" itemprop="dateCreated datePublished" datetime="2017-07-27T14:17:29+08:00">2017 年 07 月 27 日</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019 年 01 月 12 日 15:22:33" itemprop="dateModified" datetime="2019-01-12T15:22:33+08:00">2019 年 01 月 12 日</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Algorithm-and-Computer-Science/" itemprop="url" rel="index"><span itemprop="name">Algorithm and Computer Science</span></a></span>

                
                
              
            </span>
          

          
            <span class="post-meta-item" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          
          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">本文字数：</span>
              
              <span>11k</span>
            </span>
          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              
              <span>20 分钟</span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>早在学习数学分析时，我就已经接触过卷积的概念。然而，彼时年少，水平有限，没有完整地理解卷积的概念和精髓。这个遗憾一直持续至今。接触到卷积神经网络（Convolution Neural Network, CNN）之后，旧事重提般地，想要了解清楚卷积的冲动就愈发强烈，终至此文。</p>
<blockquote>
<p>这是一篇介绍性质的文章。文中的公式、动画效果限于网页的表现力，无法达至完美。本文有对应的 PDF 格式的幻灯片可供下载（<a href="//liam.page/attachment/attachment/slides/convolutions.pdf">离散卷积和卷积神经网络</a>）。你可能需要使用 <a href="https://get.adobe.com/cn/reader/" target="_blank" rel="noopener">Adobe Acrobat/Reader</a> 作为 PDF 阅读器，以获得幻灯片的所有效果。</p>
</blockquote>
<a id="more"></a>
<h2 id="初识卷积"><a href="#初识卷积" class="headerlink" title="初识卷积"></a>初识卷积</h2><h3 id="一问卷积"><a href="#一问卷积" class="headerlink" title="一问卷积"></a>一问卷积</h3><p>「卷积」这个词给人的第一印象就是「萌萌哒」，因此，恐怕很多人听见卷积的第一反应会是：「卷积<del>可以吃吗</del>为什么要叫这个名字」。</p>
<p>粗暴地回答的话，理由有三：</p>
<ul>
<li>卷在这里对应英文的 convolve 这个单词，在卷积这个概念中，它的本意是「翻转」；</li>
<li>积在这里对应乘积，因为卷积是通过两个函数/序列的乘积实现的；</li>
<li>它真的是在「卷」——把多个乘积卷在一起变成一个值。</li>
</ul>
<h3 id="形式定义"><a href="#形式定义" class="headerlink" title="形式定义"></a>形式定义</h3><p>在具体介绍卷积是什么、为什么是这样、有什么用之前，让我们预先「先入为主」地看一看一维卷积的定义是什么样的。</p>
<ul>
<li>离散形式：$(x * y)[n] = \sum_{m = -\infty}^{+\infty}x[m]\cdot y[n - m]$。</li>
<li>连续形式：$(f * g)(t) = \int_{-\infty}^{+\infty}f(\tau)\cdot g(t - \tau)\mathop{}\!\mathrm{d}\tau$。</li>
</ul>
<blockquote>
<p>当然，此篇主要介绍离散卷积，因此连续卷积从这一刻起就被暂时打入冷宫了。</p>
</blockquote>
<p>如果你仔细观察离散卷积的定义，你就会发现，它也可以写成如下等价形式。</p>
<p>$$(x * y)[n] = \sum_{i + k = n}x[i]\cdot y[k].$$</p>
<p>可以看到，卷积将等式右边的两个变量 $i$, $j$ 变成了等式左边的一个变量 $n$——俗称：降维打击。</p>
<h2 id="一维离散卷积"><a href="#一维离散卷积" class="headerlink" title="一维离散卷积"></a>一维离散卷积</h2><p>在详细介绍一维离散卷积之前，我们需要先了解什么是「线性时不变系统」。此后，在脉冲激励和冲激响应的叠加中，我们就能得到卷积。</p>
<h3 id="线性时不变系统"><a href="#线性时不变系统" class="headerlink" title="线性时不变系统"></a>线性时不变系统</h3><p><img src="/uploads/images/MachineLearning/linear_time-invariant_system.png" alt="线性时不变系统"></p>
<p>线性时不变系统（Linear Time-invariant System）是一种特殊的信号系统。它的特性分成「线性」和「时不变」两个维度。</p>
<p>所谓线性，说的是系统的输出对输入满足齐次性和叠加性。这也就是说，若输入 <code>$x_1(\tau)$</code> 和 <code>$x_2(\tau)$</code> 分别得到 <code>$y_1(\tau)$</code> 和 <code>$y_2(\tau)$</code>，那么对于任意的常数 <code>$c_1$</code>, <code>$c_2$</code> 满足 <code>$c_1x_1(\tau) + c_2x_2(\tau)$</code> 的输入在系统的作用下产生输出 <code>$c_1y_1(\tau) + c_2y_2(\tau)$</code>。</p>
<table>
<thead>
<tr>
<th>输入</th>
<th>输出</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>$x_1(\tau)$</code></td>
<td><code>$y_1(\tau)$</code></td>
</tr>
<tr>
<td><code>$x_2(\tau)$</code></td>
<td><code>$y_2(\tau)$</code></td>
</tr>
<tr>
<td><code>$c_1x_1(\tau) + c_2x_2(\tau)$</code></td>
<td><code>$c_1y_1(\tau) + c_2y_2(\tau)$</code></td>
</tr>
</tbody>
</table>
<p>所谓时不变，说的是系统对固定输入的输出响应不随时间发生变化。这也就是说，若输入 $x(\tau)$ 得到输出 $y(\tau)$，则若输入 <code>$x(t_0 + \tau)$</code> 得到输出 <code>$y(t_0 + \tau)$</code>。</p>
<table>
<thead>
<tr>
<th>输入</th>
<th>输出</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>$x(\tau)$</code></td>
<td><code>$y(\tau)$</code></td>
</tr>
<tr>
<td><code>$x(t_0 + \tau)$</code></td>
<td><code>$y(t_0 + \tau)$</code></td>
</tr>
</tbody>
</table>
<h3 id="冲激和响应"><a href="#冲激和响应" class="headerlink" title="冲激和响应"></a>冲激和响应</h3><p>信号系统的输入，称之为「激励」。对信号系统来说，它通常会接收一连串的激励。这一连串的激励，通常在瞬时发生，然后消退。因此信号系统的输入又称之为「脉冲激励」，简称「冲激」。若以 $y$ 记信号系统的冲激，则它应该是一个序列 $y[n]$。具体的值 $y[i]$ 或 $y_i$ 表示第 $i$ 时刻信号系统接收的脉冲激励。</p>
<p><code>$$y[n] = \{ \ldots, y_{-1} = 0, y_0 = i, y_1 = j, y_2 = k, y_3 = 0, \ldots \}.$$</code></p>
<p>信号系统的输出，称之为「响应」。对于单位强度冲激的响应，即是「冲激响应」。信号系统对单独的冲激，做出的响应输出，可能在冲激发生之后持续一段时间。若以 $x$ 记信号系统的冲激响应，则它也应该是一个序列 $x[n]$。具体的值 $x[i]$ 或 $x_i$ 表示系统接收到单位强度冲激之后第 $i$ 时刻做出的响应输出。</p>
<blockquote>
<p>若你不太理解为何响应会在冲激发生之后持续一段时间，那么你可以把自己比作一个信号系统。当你遇到什么开心/不开心的事情之后，你高兴/伤心的情绪不会只在那一瞬间出现，而是会持续一段时间。</p>
</blockquote>
<p><code>$$x[n] = \{ \ldots, x_{-1} = 0, x_0 = a, x_1 = b, x_2 = c, x_3 = 0, \ldots \}.$$</code></p>
<h3 id="连续冲激的响应"><a href="#连续冲激的响应" class="headerlink" title="连续冲激的响应"></a>连续冲激的响应</h3><p>现在我们知道几个事实：</p>
<ul>
<li>系统接收到一份输入后，其后的一段时间内会陆续给出输出响应；</li>
<li>系统会连续收到若干输入；</li>
<li>系统是线性时不变的。</li>
</ul>
<p>特别地，输入冲激 $\hat y$ 在 $x[n]$ 的作用下，第 $i$ 时刻的输出是 $\hat y\cdot x[i]$。因此，整个线性时不变系统在第 $i$ 时刻的输出，应该是<br>$$y[0]\cdot x[i] + y[1]\cdot x[i - 1] + \cdots.$$<br>当然，对于两端延伸的无穷序列，你应该把它写作<br>$$\cdots + y[-1]\cdot x[i + 1] + y[0]\cdot x[i] + y[1]\cdot x[i - 1] + \cdots.$$</p>
<p>以上一小节的数据为例，将数据制成表如下：</p>
<table>
<thead>
<tr>
<th>time</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
</tr>
</thead>
<tbody>
<tr>
<td>$y_0 = i$</td>
<td>$ai$</td>
<td>$bi$</td>
<td>$ci$</td>
<td>$0$</td>
<td>$0$</td>
</tr>
<tr>
<td>$y_1 = j$</td>
<td>$0$</td>
<td>$aj$</td>
<td>$bj$</td>
<td>$cj$</td>
<td>$0$</td>
</tr>
<tr>
<td>$y_2 = k$</td>
<td>$0$</td>
<td>$0$</td>
<td>$ak$</td>
<td>$bk$</td>
<td>$ck$</td>
</tr>
</tbody>
</table>
<p>接下来，你只需要纵向观察表格，将每一纵列的值相加，就能得到相应时刻的系统输出响应了。</p>
<h3 id="离散卷积"><a href="#离散卷积" class="headerlink" title="离散卷积"></a>离散卷积</h3><p>从上面的分析中，可以看出，对于任意时刻 $n$，系统的输出是</p>
<p><code>$$z[n] \overset{\text{def}}{=} (x*y)[n] = \sum_{m = -\infty}^{+\infty}x[n - m]\cdot y[m] = \sum_{m = -\infty}^{+\infty}x[m]\cdot y[n - m].$$</code></p>
<p>这正是一维离散卷积的定义。以 <code>$\sum_{m = -\infty}^{+\infty}x[m]\cdot y[n - m]$</code> 为例，不难发现，卷积其实是一种推广的加权平均：以 $x$ 为权，以 $n$ 为中心，把 $y$ 距离中心 $-m$ 位置上的值乘上 $x$ 在 $m$ 位置的值，最后加到一起。</p>
<h3 id="定投的例子"><a href="#定投的例子" class="headerlink" title="定投的例子"></a>定投的例子</h3><p>现在假设有一个一年期定投项目，它的利率始终保持不变。因此，整个定投项目可以视作是一个线性时不变系统。</p>
<ul>
<li>最终收益对投入的资金是线性累加的；</li>
<li>利率不变，意味着任何时候投入资金的效果是一样的。</li>
</ul>
<p>因此，你可以定义响应序列</p>
<p><code>$$x[n] = \{ \ldots, x_{-1} = 0, x_0 = 1.05^0, x_1 = 1.05^1, \ldots, x_i = 1.05^i, \ldots \}.$$</code></p>
<p>而后，假设你每年存入 100 元，于是有冲激序列</p>
<p><code>$$y[n] = \{ \ldots, y_{-1} = 0, y_0 = 100, y_1 = 100, \ldots, y_i = 100, \ldots \}.$$</code></p>
<p>于是，任意时刻的账户余额 $z[n] \overset{\text{def}}{=} (x*y)[n]$ 是卷积。</p>
<table>
<thead>
<tr>
<th>time</th>
<th>$0$</th>
<th>$1$</th>
<th>$2$</th>
<th>$3$</th>
<th>$4$</th>
</tr>
</thead>
<tbody>
<tr>
<td>$y_0 = 100$</td>
<td>$100$</td>
<td>$100\times 1.05^1$</td>
<td>$100\times 1.05^2$</td>
<td>$100\times 1.05^3$</td>
<td>$100\times 1.05^4$</td>
</tr>
<tr>
<td>$y_1 = 100$</td>
<td>$0$</td>
<td>$100$</td>
<td>$100\times 1.05^1$</td>
<td>$100\times 1.05^2$</td>
<td>$100\times 1.05^3$</td>
</tr>
<tr>
<td>$y_2 = 100$</td>
<td>$0$</td>
<td>$0$</td>
<td>$100$</td>
<td>$100\times 1.05^1$</td>
<td>$100\times 1.05^2$</td>
</tr>
<tr>
<td>$y_3 = 100$</td>
<td>$0$</td>
<td>$0$</td>
<td>$0$</td>
<td>$100$</td>
<td>$100\times 1.05^1$</td>
</tr>
<tr>
<td>$y_4 = 100$</td>
<td>$0$</td>
<td>$0$</td>
<td>$0$</td>
<td>$0$</td>
<td>$100$</td>
</tr>
</tbody>
</table>
<p>接下来，我们回过头观察 <code>$\sum_{m = -\infty}^{+\infty}x[m]\cdot y[n - m]$</code> 这个式子。</p>
<p>若以 $m$ 为「自变量」，则 $y[n - m]$ 相当于把 $y[m]$ 的图像左右翻转（这即是<strong>翻转</strong>的来源），然后再向右移动 $n$ 个单位。而当 $n$ 增大时，相当于 $x$ 不动而 $y$ 沿着轴线向右滑动。当 $x$ 和 $y$ 重叠时，计算重叠部分的乘积，然后加和得到最终结果。这个加和的过程，放在连续函数的情景下，就是积分了。将这个过程，制作成动态图如下。</p>
<p><img src="/uploads/images/MachineLearning/automatic_investment_plan.gif" alt="定投收益示意图"></p>
<h3 id="怎样卷？"><a href="#怎样卷？" class="headerlink" title="怎样卷？"></a>怎样卷？</h3><p>通过观察 <code>$\sum_{m = -\infty}^{+\infty}x[m]\cdot y[n - m]$</code>，我们已经知道了卷积是怎样翻转的，也知道卷积的积分从何而来。现在我们讨论关于卷积的终极问题：究竟要怎样才能「卷起来」？</p>
<p><img src="/uploads/images/MachineLearning/how_to_convolve.png" alt="怎样卷起来"></p>
<p>我们来看这张图。它的横轴和纵轴被替换成了 $m$ 和 $n - m$，恰好对应 <code>$\sum_{m = -\infty}^{+\infty}x[m]\cdot y[n - m]$</code> 中的 $x[m]$ 和 $y[n - m]$。途中有两条斜线，斜线经过的整数交点上画着小黑点。这些小黑点代表相应位置的 $x[m]\cdot y[n - m]$；而斜线则代表将这条斜线上所有小黑点的值相加。</p>
<p>不难发现，$m(n-m)$-二维平面上斜率为 $-1$ 的斜线族，其中每条这样的斜线（包括没有画出来的），都表示了一个卷积。特别地，斜线上每一个整数点的横纵坐标相加（即是 $m + (n - m)$）都是 $n$。因此，斜线对应的卷积是 $(x * y)[n]$。这样，我们就建立了斜线与卷积值之间的对应关系。</p>
<p>现在，把 $m(n-m)$-二维平面想象成一块无限薄的地毯。接下来，我们沿着斜率为 $-1$ 的直线方向，把地毯卷起来。这样，我们就将地毯卷成了一条直线。而这条直线上的每个点，都对应了原平面上的一条直线。也就是说，在「卷地毯」的过程中，原平面的直线纷纷坍缩成了一系列的点。而这些轴线与其上的点，正可作为是卷积 $(x*y)[n]$ 中 $n$ 所在的数轴。</p>
<p>这就是为什么我们说，卷积它真的可以「卷」了。</p>
<h3 id="二问卷积"><a href="#二问卷积" class="headerlink" title="二问卷积"></a>二问卷积</h3><p>至此，一维离散卷积相关的内容，我们就介绍完了。现在我们回过头来看看，在介绍一维离散卷积的过程中，卷积表现出了哪些特点。</p>
<p>我们是通过线性时不变的信号系统引出卷积的概念的。若仍以信号系统的说辞为例，则不难发现：</p>
<ul>
<li>一个脉冲激励可以影响到信号系统在若干时刻的输出；</li>
<li>从另一个角度，这也就是说，信号系统任意时刻的输出，取决于相关的多个冲激输入。</li>
</ul>
<p>也就是说，和一般的函数不同，信号系统的输入和输出不是「一对一」的关系，而是「多对多」的关系。我们在后续介绍卷积神经网络的时候，会看到这一特点的作用。</p>
<p>此外，仍以信号系统的说辞为例，我们也不难发现，系统的最终输出，一方面取决于输入的激励信号长什么样子，另一方面取决于冲激响应的模式。这两方面相互作用（就是卷积），最终决定了信号系统的输出。</p>
<p>在后续对一维离散卷积的观察中，我们发现，连续地求解多个卷积值的时候（即，求解 $n = 0, 1, 2, \ldots$ 的卷积值时），我们实际上做的事情可以归纳成：</p>
<ul>
<li>翻转输入信号；</li>
<li>输入信号沿轴线向前滑动；</li>
<li>输入信号与冲激响应叠加的部分分别求积，然后相加。</li>
</ul>
<p>而实际上我们发现，在卷积的定义中，$x$ 和 $y$ 是地位等同的。这就是说，我们也完全可以选择翻转而后滑动冲激响应的模式，再去求积、叠加。此时，我们通常会把冲激响应称为「卷积核」，而把整个过程形象地称之为：滑动卷积核。</p>
<h2 id="二维离散卷积"><a href="#二维离散卷积" class="headerlink" title="二维离散卷积"></a>二维离散卷积</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>恭喜你，现在我们进入「高维宇宙」。</p>
<p>首先，让我们回顾一下一维离散卷积的定义。</p>
<p><code>$$(x*y)[n] \overset{\text{def}}{=} \sum_{m = -\infty}^{+\infty}x[m]\cdot y[n - m].$$</code></p>
<p>二维卷积的定义，在形式上和一维卷积完全一致——只需要将一维卷积中的变量 $m$, $n$ 从标量变成向量即可。当然，你也可以将向量的两个分量展开，记成标量形式。</p>
<p><code>$$
\begin{aligned}
(x*y)[\vec n] \overset{\text{def}}{=}{}&amp; \sum_{\vec m = (-\infty, -\infty)}^{(+\infty, +\infty)}x[\vec m]\cdot y[\vec n - \vec m] \\
(x*y)[n_1, n_2] \overset{\text{def}}{=}{}&amp; \sum_{m_1 = -\infty}^{+\infty}\sum_{m_2 = -\infty}^{+\infty}x[m_1, m_2]\cdot y[n_1 - m_1, n_2 - m_2].
\end{aligned}
$$</code></p>
<blockquote>
<p>类似地，你可以定义更高维的卷积。</p>
</blockquote>
<p>若仔细观察公式，不难发现，我们在二维卷积中遇到的问题，和在一维卷积中遇到的问题完全一致。二维卷积具有和一维卷积几乎完全相同的性质、特点、作用。和一维卷积一样，二维卷积也可以看做是加权平均的推广：以 $x$ 为权，以 <code>$(n_1, n_2)$</code> 位中心，将 $y$ 距离中心 <code>$(-m_1, -m_2)$</code> 位置的值乘上 $x$ 距离中心 <code>$(m_1, m_2)$</code> 的值，最后加到一起。</p>
<h3 id="图像的滤镜"><a href="#图像的滤镜" class="headerlink" title="图像的滤镜"></a>图像的滤镜</h3><p>在实际应用中，卷积核 $x$ 的有效部分总是有限的。例如，下图展示了一个 $3\times 3$ 的卷积核，在图像上的滑动。</p>
<p><img src="/uploads/images/MachineLearning/convolutions_on_images.gif" alt="二维卷积示意图"></p>
<p>值得一提的是，对于图像来说，这个过程实际就是 PhotoShop 等图像处理软件中的「滤镜」效果。比如，假设我们有一个 $3\times 3$ 的卷积核</p>
<p><code>$$
\begin{bmatrix}
1/9 &amp; 1/9 &amp; 1/9 \\
1/9 &amp; 1/9 &amp; 1/9 \\
1/9 &amp; 1/9 &amp; 1/9
\end{bmatrix},
$$</code></p>
<p>从直觉上分析，它将中心点附近的共 9 个点的像素值，平均到输出图像的中心像素点上；这实际上就是模糊效果对应的滤镜（box-blur）。又比如，假设我们有这样的卷积核</p>
<p><code>$$
\begin{bmatrix}
0 &amp; -1 &amp; 0  \\
-1 &amp; 5 &amp; -1 \\
0 &amp; -1 &amp; 0  \\
\end{bmatrix},
$$</code></p>
<p>从直觉上分析，它加强了中心像素点的作用，同时减小了位于其上下左右的四个像素点对它的干扰；这实际上就是锐化效果对应的滤镜（sharpen）。又比如，假设我们有这样的卷积核</p>
<p><code>$$
\begin{bmatrix}
-1 &amp; -1 &amp; -1 \\
-1 &amp; 8 &amp; -1  \\
-1 &amp; -1 &amp; -1 \\
\end{bmatrix},
$$</code></p>
<p>从直觉上分析，只有当中心像素点原本的像素值和周围 8 个像素点的值差距很大时，这个卷积核的输出，才会明显地不等于 0；因此，这实际上就是边缘检测对应的滤镜（edge detect）。</p>
<p>我们将上述三个矩阵以 Python 实现出来，就能看到它们的效果了。（参见：<a href="/2017/08/06/pil-tutorial-pixel-operations-and-image-filter/#实际操作看看——实现卷积滤镜">PIL 简明教程 - 像素操作与图像滤镜</a>）其效果如下图所示。</p>
<p><img src="/uploads/images/MachineLearning/image_filter.png" alt="Python 实现的图像滤镜"></p>
<h3 id="三问卷积"><a href="#三问卷积" class="headerlink" title="三问卷积"></a>三问卷积</h3><p>又到了思考问题的<del>贤者</del>时间。</p>
<p>在介绍一维卷积的过程中，我们已经讨论了卷积本身具有的特点。但是，也留下了一个问题：卷积在抽象上，到底有什么意义呢？</p>
<p>站在人类的角度，我们先入为主地将上面 3 个示例的卷积核当做了「滤镜」。然而，事情真的是这样吗？如果我们忘记「滤镜」这一先验知识，那么我们可能会把这件事情，简单地以更抽象的方式描述为「卷积核<strong>处理</strong>图形」。没错，这仅仅是一个「处理」过程而已。现在我们回想一下，环境中的真实景象，也是经过我们的大脑处理之后，在脑海里形成实际的画面的。若然你知道，同一个真实景象，在不同生物的眼里是不一样的。那么你就不难发现，不同的生物，因其进化路径不同，大脑对环境真实景象的处理也不同，因而脑海中看到的景象也就不同。这与我们用不同的滤镜处理图像，得到不同的滤镜结果，何其相似？</p>
<p>刚才我们说到不同生物眼里的世界是不一样的。那么，更深入地理解一下这份不同，我们会否领会到更多的东西呢？</p>
<p>比如，我们可以思考：为什么自然选择会让不同的生物看到不同的景象？答案其实很简单：因为适者生存。蛇类的眼睛，按照人类的意识，几乎不能视物；然而因为经常需要夜间活动，所以蛇能够以红外的方式「看到」这个世界。青蛙的眼睛，难以察觉到静止的事物；然而因为它只对「会动的虫子」感兴趣，所以青蛙具有奇佳的动态视觉。站在更广的时间维度上，我们可以这样回答这个问题：对于具体的某种生物来说，因其生存需要，它只对某种形式的视觉效果感兴趣，因而其视觉处理系统进化成了当前的模样。简而言之，不同的生物，看待世界的方式，有不同的侧重点，因而将同一个真实景象处理成了不同的模样。</p>
<p>这里我们对生物的视觉效果进行了展开分析。这不是我要「跨界」当「神棍」，而是想以一种直觉的方式，以普遍的现象为对比，试着能够更好地理解卷积的意义。</p>
<p>至此，我们可以比较容易地制作出一张对应的表格。</p>
<table>
<thead>
<tr>
<th>卷积</th>
<th>生物视觉</th>
<th>机器学习领域的意义</th>
</tr>
</thead>
<tbody>
<tr>
<td>滑动卷积核</td>
<td>视觉系统处理外界光信号</td>
<td>读入并处理结构化的特征</td>
</tr>
<tr>
<td>卷积核处理的结果</td>
<td>脑海中形成的视觉成像</td>
<td>卷积处理的结果</td>
</tr>
<tr>
<td>不同的卷积核</td>
<td>观察世界的不同方式、不同侧重点</td>
<td>不同角度的高维特征信号</td>
</tr>
</tbody>
</table>
<p>这也就是说，特定的卷积核，能够从<strong>若干相关特征信号</strong>（通常是相邻位置的特征信号）中<strong>以特定的方式</strong>抽取新的高维特征。</p>
<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>有了这些关于卷积的知识基础，现在我们可以讨论卷积神经网络了。我们假设你已经对神经网络有所了解，因此就不去从感知机开始，逐步地介绍了。</p>
<h3 id="图片识别任务"><a href="#图片识别任务" class="headerlink" title="图片识别任务"></a>图片识别任务</h3><blockquote>
<p>这个例子，来自于 <a href="https://zhuanlan.zhihu.com/p/27642620" target="_blank" rel="noopener">YJango的卷积神经网络——介绍</a>。</p>
</blockquote>
<p>在介绍二维离散卷积的时候，我们以图片为例。这是因为，图片是天然的二维像素矩阵组成的数据形式（RBG 三通道即是 3 个矩阵）。因此，专业里我们也以图片识别任务为例，展开对卷积神经网络的介绍。</p>
<p><img src="/uploads/images/MachineLearning/pattern_reg_target.png" alt="识别横折"></p>
<p>如上图。每一个 $4 \times 4$ 的方块，都表示一张图片。在我们的表示中，黄色的圆圈表示空无一物的底色；黑色的圆圈，表示有内容的笔画。现在，我们要识别上图顶部的「横折」这一笔画。显而易见，上图下半部分的 6 张图片，内里都包含了横折。</p>
<h3 id="前馈神经网络"><a href="#前馈神经网络" class="headerlink" title="前馈神经网络"></a>前馈神经网络</h3><p>对于这样的图片识别任务，使用深度前馈神经网络来解决，当然是可以的。</p>
<p><img src="/uploads/images/MachineLearning/pattern_reg_dnn.png" alt="深度神经网络（DNN）图例"></p>
<p>如上图。为了解决这样的问题，我们首先需要将原始图片制成一个能用向量表示出来的数据形式。最简单的办法，就是将二维的图像，逐行地展开。如此，我们就从 <code>object</code> 得到了输入层 <code>input</code>。接下来，我们就可以把输入层链接到隐藏层当中，经过逐层地全连接，得到最终输出 <code>output</code>。通常来说，这个最终输出，是神经网络给出的概率。这个概率描述，神经网络认为当前图片中，包含「横折」的概率。</p>
<p>经过大量的训练，这样的神经网络可以很好地完成识别任务。然而，这样的网络设计，也可能存在一些问题。</p>
<p><img src="/uploads/images/MachineLearning/pattern_reg_cases.png" alt="图片识别样本"></p>
<p>如上图。假设左侧的 4 张图片，是我们标注好的训练样本。经过训练之后，我们的神经网络应当已经具有一定的能力，尝试识别图片中是否存在「横折」这一笔画。然而，由于训练神经网络时的输入样本十分有限，我们的神经网络可能并不认得右侧的样本。特别地，在我们的神经网络示意图中，左上角的横折和位于中间的横折是完全不同的两个向量。因此，我们得到的神经网络模型，很可能无法给出对右侧未知样本的准确预测。</p>
<p>那么，怎么办呢？</p>
<p>最最简单容易想到的办法，就是增加训练时的训练样本。若然我们能够让样本覆盖所有情况，那么训练得到的神经网络自然就可以识别所有的情况，并给出结论了。不过，最简单容易想到的解法，往往暗含各种各样的问题。首先，我们的图片识别任务中，图片都是 $4 \times 4$ 的小型图片。对这类图片，穷举所有可能，其总数也只有 $2^{16}$ 张。对于这种类型的问题，穷举所有情况，大致是没有问题的。然而，实际生产中，我们遇到的问题，其复杂度要远远高于现在我们所言的「玩具问题」。在实际问题中，我们不可能让样本覆盖所有情形。另一方面，若是简单粗暴地扩增样本容量，就失去了模型「预测」的意义了。换而言之，这就不是我们追求的高可泛化的模型了。</p>
<h3 id="表意的平移不变性——对问题的深入思考"><a href="#表意的平移不变性——对问题的深入思考" class="headerlink" title="表意的平移不变性——对问题的深入思考"></a>表意的平移不变性——对问题的深入思考</h3><p>扩大训练集的解法，当然也是一个办法。在实际生产中，有些时候也确实需要扩大训练集，以解决一些欠拟合的问题。然而，正如任何定理都有其适用范围，我们也需要斟酌扩大训练集在当前任务中是否合适。显然，有上面的分析，在当前任务中，这不是个好办法。</p>
<p>那么，问题出在哪里呢？或者说，我们应当在哪个方向前进，以便解决这个问题呢？在上面的分析中，我们有提到一句话：「在我们的神经网络示意图中，左上角的横折和位于中间的横折是完全不同的两个向量」。我想，若你足够敏感，应该能意识到什么。</p>
<p>不好。这很不好。在表意上，位于图片左上角的横折之于位于图片中间的横折没有什么差别。也就是说，在图片上任意平移横折的位置，其表意不发生变化。我们称之为表意的平移不变性。然而，在我们的神经网络中，这两个横折在输入层的表现居然没有什么共同点。显而易见，这是不合理的。因此，在遇到的这个问题中，我们首先应该考虑的，不是扩增训练集，而是应当考虑我们神经网络是否足够好地适应当前的问题。</p>
<p>那么，我们的神经网络中，问题出在哪里呢？</p>
<p>首先，我们的神经网络是针对每个像素的具体情况进行训练的。其次，图片上的区域各自为政，没有关联。也就是说，我们的神经网络，很难捕捉到相邻区域中几个像素点（特征值）的结构信息。另一方面，我们的神经网络，也没有以一种一致地视角，去看待每一个局部的结构。这样一来，我们的神经网络就可能会把位于左上角的横折与位于中间的横折，当成两个完全没有关联的图形。这显然是不合适的。</p>
<h3 id="引入卷积"><a href="#引入卷积" class="headerlink" title="引入卷积"></a>引入卷积</h3><p>至此，就轮到卷积出场<del>拯救世界</del>了。</p>
<p>我们回顾一下简单的前馈神经网络在当前任务中遇到的问题：无法一致地捕捉局部的结构信息。我们再来回想一下卷积的特点：以一个固定的卷积核，收集相邻特征信号的信息，加权平均得到卷积值。啊！卷积的这些特点，不就正好弥补了当前前馈神经网络的不足吗？</p>
<p>于是，我们可以设计出这样的网络结构。</p>
<p><img src="/uploads/images/MachineLearning/pattern_reg_cnn.png" alt="卷积神经网络（CNN）图例"></p>
<p>如上图。首先，我们用一个固定的 $2 \times 2$ 的卷积核作为窗口，逐个像素地扫描原图片。这样一来，我们可以得到 $3 \times 3$ 的卷积结果，称为 <code>convolved feature</code>。而后，和我们在前馈神经网络中做的一样，我们将 <code>convolved feature</code> 展开，作为输入层，链接其背后的隐藏层，并最终得到输出。</p>
<p>在这个过程中，神经网络的参数，除了隐藏层中的各个神经元上的参数，还有卷积核的具体内容。也就是说，卷积核的大小是固定的，但是它长什么样子，是需要具体训练的。</p>
<p>这样引入了卷积的神经网络，就是卷积神经网络（Convolution Neural Network, CNN）了。当然，在实际使用中，还常常引入名为池化（Pooling）的技术，这里按下不表。</p>
<h3 id="不变性的讨论"><a href="#不变性的讨论" class="headerlink" title="不变性的讨论"></a>不变性的讨论</h3><p>有了卷积，我们的神经网络就能一致地去捕捉输入信号局部的结构信息。特别地，由于卷积核在不同位置上是共享的，所以笔画的平移在神经网络看来，就不影响表意了。因此我们说，卷积神经网络满足了平移不变性。</p>
<p>那么，是否还有其它的不变性呢？当然是有的。</p>
<p>比如，我们现在的横折由 $3$ 个像素在 $2 \times 2$ 的局部中组成。那么，若是将它放大，在 $3 \times 3$ 的局部中，用 $5$ 个像素去组成横折，是否也可以呢？答案是显而易见的：大猫也是猫，大狗也是狗。这种现象，我们称之为缩放不变性。那么，当前的卷积神经网络，是否能解决这样的问题呢？我们说，不能。因为我们当前使用的卷积核是 $2 \times 2$ 的，它无法去捕捉 $3 \times 3$ 的局部结构中的完整信息。因此，当前的卷积神经网络，没有满足缩放不变性。若要满足缩放不变性，我们可以考虑用不同大小的卷积核，分别处理原图像；或者，可以考虑在卷积层的基础上，再用卷积处理一次。</p>
<p>又比如，假设我们不识别笔画，我们识别图片中的铅笔。在图片中，除了说铅笔可大可小，位置上可以在图片上游走，铅笔还可能以不同角度出现——横着放的、竖着放的、斜着放的。但不论铅笔如何摆放，它都是铅笔。这种现象，我们称之为旋转不变性。不过，很遗憾，由于卷积的特性所限，我们无法简单地用卷积，让神经网络满足旋转不变性。</p>
<h3 id="卷积神经网络直觉上的优势"><a href="#卷积神经网络直觉上的优势" class="headerlink" title="卷积神经网络直觉上的优势"></a>卷积神经网络直觉上的优势</h3><p>上面我们讨论了卷积的特点。因此，我们不难总结卷积神经网络的一些优势。</p>
<ul>
<li>适用于相关元素（特别是相邻元素）中存在结构特征的情况；</li>
<li>适用于上述结构可能出现在不同位置的情况。</li>
</ul>
<p>现在，我们考虑一下分类问题。对于分类问题来说</p>
<ul>
<li>在分割线（可能是超平面、超曲面）附近，样本往往存在特定的结构特征；</li>
<li>输入的样本，可能位于分割线的不同位置，因此上述结构也可能出现在分割线的不同位置。</li>
</ul>
<p>分类问题的这样的特点，恰恰符合了卷积神经网络的优势。因此，人们常常偏向于认为：「卷积神经网络可以在分类问题上表现得好」。</p>

    </div>

    
    
    
        
      
        <div id="reward-container">
  <div>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">

    
      
      
        
        
          
        
        <div style="display: inline-block">
          <img src="/images/reward/wechatpay-cropped.png" alt="Liam Huang 微信支付"/>
          <p>微信支付</p>
        </div>
      
    
      
      
        
        
          
        
        <div style="display: inline-block">
          <img src="/images/reward/alipay-cropped.png" alt="Liam Huang 支付宝"/>
          <p>支付宝</p>
        </div>
      
    
      
      
    
      
      
    

    
      <div id="paypal" style="display: inline-block">
        <!-- <img id="paypal_qr" src="/" alt="Liam Huang PayPal"/> -->
        <img id="paypal_form">
          <form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
          <input type="hidden" name="cmd" value="_donations" />
          <input type="hidden" name="business" value="3EKTTVF2FF5EQ" />
          <input type="hidden" name="item_name" value="If you like my blog, please consider to buy a cup of coffee for me. Thanks!" />
          <input type="hidden" name="currency_code" value="USD" />
          <input type="image" src="/images/reward/paypal-btn_donateCC_LG.gif" border="0" name="submit" />
          </form>
        </img>
        <p>PayPal</p>
      </div>
    

  </div>
</div>

      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Liam Huang</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://liam.page/2017/07/27/convolutions-and-convolution-neural-network/" title="谈谈离散卷积和卷积神经网络">https://liam.page/2017/07/27/convolutions-and-convolution-neural-network/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>
</div>

      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/Convolutions/" rel="tag"># Convolutions</a>
            
              <a href="/tags/CNN/" rel="tag"># CNN</a>
            
              <a href="/tags/Neural-Network/" rel="tag"># Neural Network</a>
            
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2017/07/23/global-scale-for-TikZ-picture/" rel="next" title="在 LaTeX 中同步缩放 TikZ 与其中的 node">
                  <i class="fa fa-chevron-left"></i> 在 LaTeX 中同步缩放 TikZ 与其中的 node
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2017/07/30/define-a-new-command-with-different-amount-of-parameters-in-LaTeX/" rel="prev" title="LaTeX 黑魔法（三）：定义参数变长的命令">
                  LaTeX 黑魔法（三）：定义参数变长的命令 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    <div class="comments" id="gitalk-container"></div>
  

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          文章目录
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#初识卷积"><span class="nav-number">1.</span> <span class="nav-text">初识卷积</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#一问卷积"><span class="nav-number">1.1.</span> <span class="nav-text">一问卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#形式定义"><span class="nav-number">1.2.</span> <span class="nav-text">形式定义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#一维离散卷积"><span class="nav-number">2.</span> <span class="nav-text">一维离散卷积</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#线性时不变系统"><span class="nav-number">2.1.</span> <span class="nav-text">线性时不变系统</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#冲激和响应"><span class="nav-number">2.2.</span> <span class="nav-text">冲激和响应</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#连续冲激的响应"><span class="nav-number">2.3.</span> <span class="nav-text">连续冲激的响应</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#离散卷积"><span class="nav-number">2.4.</span> <span class="nav-text">离散卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#定投的例子"><span class="nav-number">2.5.</span> <span class="nav-text">定投的例子</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#怎样卷？"><span class="nav-number">2.6.</span> <span class="nav-text">怎样卷？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二问卷积"><span class="nav-number">2.7.</span> <span class="nav-text">二问卷积</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二维离散卷积"><span class="nav-number">3.</span> <span class="nav-text">二维离散卷积</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#定义"><span class="nav-number">3.1.</span> <span class="nav-text">定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#图像的滤镜"><span class="nav-number">3.2.</span> <span class="nav-text">图像的滤镜</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#三问卷积"><span class="nav-number">3.3.</span> <span class="nav-text">三问卷积</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积神经网络"><span class="nav-number">4.</span> <span class="nav-text">卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#图片识别任务"><span class="nav-number">4.1.</span> <span class="nav-text">图片识别任务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#前馈神经网络"><span class="nav-number">4.2.</span> <span class="nav-text">前馈神经网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#表意的平移不变性——对问题的深入思考"><span class="nav-number">4.3.</span> <span class="nav-text">表意的平移不变性——对问题的深入思考</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#引入卷积"><span class="nav-number">4.4.</span> <span class="nav-text">引入卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#不变性的讨论"><span class="nav-number">4.5.</span> <span class="nav-text">不变性的讨论</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积神经网络直觉上的优势"><span class="nav-number">4.6.</span> <span class="nav-text">卷积神经网络直觉上的优势</span></a></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar/avatar.webp"
      alt="Liam Huang">
  <p class="site-author-name" itemprop="name">Liam Huang</p>
  <div class="site-description" itemprop="description">不忘初心，方得始终。</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">300</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">599</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    
  
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      友情链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://anyi.im/" title="https://anyi.im/" rel="noopener" target="_blank">Anyi</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="https://xixiaoyao.github.io/" title="https://xixiaoyao.github.io/" rel="noopener" target="_blank">Xiyao</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="http://yemengying.com/" title="http://yemengying.com/" rel="noopener" target="_blank">Giraffe</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="http://www.jellythink.com/" title="http://www.jellythink.com/" rel="noopener" target="_blank">JellyThink</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="http://jiayu.lu/" title="http://jiayu.lu/" rel="noopener" target="_blank">Jiayu</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="http://qixinbo.info/" title="http://qixinbo.info/" rel="noopener" target="_blank">XinboQi</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="http://www.shuang0420.com" title="http://www.shuang0420.com" rel="noopener" target="_blank">AhengXu</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="http://www.fuzihao.org" title="http://www.fuzihao.org" rel="noopener" target="_blank">FuZihao</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="https://ionizing.page/" title="https://ionizing.page/" rel="noopener" target="_blank">ChenLinjie</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="https://yihui.name/" title="https://yihui.name/" rel="noopener" target="_blank">Yihui</a>
        </li>
      
        <li class="links-of-blogroll-item">
          <a href="https://blog.felixc.at/" title="https://blog.felixc.at/" rel="noopener" target="_blank">Felix</a>
        </li>
      
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2013 – <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liam Huang</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">1.1m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">34:46</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" id="busuanzi_container_site_pv" title="总访问量" style='display:none'>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>


<script src="/js/liam/tools.js"></script>
<script>
  ready(function() {
    
    
    var intervalTotalViews = setInterval(fixTotalViews, 100);
    var offsetTotalViews   = parseInt(100000);
    function fixTotalViews() {
      if (getStyleByID("busuanzi_container_site_pv", "display") != "none") {
        clearInterval(intervalTotalViews);
        var el = document.getElementById("busuanzi_value_site_pv");
        var value = parseInt(el.innerHTML) + offsetTotalViews;
        el.innerHTML = '' + value;
      }
    }
    
  });
</script>














        
      </div>
    </footer>
  </div>

  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>

<script src="/js/next-boot.js?v=7.3.0"></script>



  








  <script src="/js/local-search.js?v=7.3.0"></script>














<script type="text/javascript">
var crashSwitched = false;
var originalTitle = document.title;
var titleTime;
document.addEventListener('visibilitychange', function () {
  if (document.hidden) {
    if (Math.random() < parseFloat(0.25)) {
      crashSwitched = true;
      document.title = '╭(°A°`)╮ 页面崩溃啦~' + originalTitle;
      clearTimeout(titleTime);
    }
  } else {
    if (crashSwitched == true) {
      crashSwitched = false;
      document.title = '(ฅ>ω<*ฅ) 咦，又好了~' + originalTitle;
      titleTime = setTimeout(function () {
        document.title = originalTitle;
      }, 2000);
    }
  }
});
</script>




  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
        extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js"],
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

<script type="text/javascript">
$(document).ready(function(){
  $("code").map(function(){
    match = /^\$(.*)\$$/.exec($(this).html());
    if (match) {
      $(this).replaceWith("<span class=hpl_mathjax_inline>" + $(this).html() + "</span>");
      MathJax.Hub.Queue(["Typeset",MathJax.Hub,$(this).get(0)]);
      return;
    }
    match = /^\$\$/.exec($(this).html());
    if (match) {
      $(this).replaceWith("<span class=hpl_mathjax_inline>" + $(this).html() + "</span>");
      MathJax.Hub.Queue(["Typeset",MathJax.Hub,$(this).get(0)]);
      return;
    }
    match = /^\\begin/.exec($(this).html());
    if (match) {
      $(this).replaceWith("<span class=hpl_mathjax_inline>" + $(this).html() + "</span>");
      MathJax.Hub.Queue(["Typeset",MathJax.Hub,$(this).get(0)]);
      return;
    }
  });
});
</script>

    
  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: 'a3d846b3392f468b5746',
      clientSecret: '61bc947cad0ec7078e800e05b1e3c78b763b2c55',
      repo: 'liam0205.github.io',
      owner: 'Liam0205',
      admin: ['Liam0205'],
      id: '63d1dda790a1d976ab0605fd00a680c6',
        language: 'zh-CN',
      
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script>

</body>
</html>
